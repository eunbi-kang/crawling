from sentence_transformers import util
import numpy as np
from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
from konlpy.tag import Mecab
import re

# âœ… MongoDB ì—°ê²°
MONGO_URI = "mongodb://eunbikang:1234@localhost:27017/admin"
client = MongoClient(MONGO_URI)
db = client["admin"]
collection = db["latest_news"]

# âœ… í•œêµ­ì–´ SBERT ëª¨ë¸ (768ì°¨ì›)
model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")

# âœ… Mecab í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œ
mecab = Mecab()

# âœ… í˜•íƒœì†Œ ë¶„ì„ í‚¤ì›Œë“œ ì¶”ì¶œ (ğŸ”¥ ì¤‘ë³µ ì œê±° ì¶”ê°€)
def extract_keywords(title, summary):
    title_keywords = mecab.nouns(title) if title else []
    summary_keywords = mecab.nouns(summary) if summary else []
    keywords = list(set(title_keywords + summary_keywords))  # âœ… ì¤‘ë³µ ì œê±°

    if len(keywords) < 5:
        return (title + " " + summary).strip()
    return " ".join(keywords)

# âœ… **BM25 ë˜ëŠ” ë¬¸ìì—´ í¬í•¨ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜**
def compute_text_match_score(query, text):
    query_terms = query.split()
    match_count = sum(1 for term in query_terms if re.search(term, text, re.IGNORECASE))  # âœ… ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ê²€ìƒ‰

    return match_count / len(query_terms) if query_terms else 0  # âœ… 0~1 ì‚¬ì´ ê°’ ë°˜í™˜

# âœ… **ìœ ì‚¬ë„ ê¸°ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰ (ğŸ”¥ SBERT ìœ ì‚¬ë„ + ë¬¸ìì—´ í¬í•¨ ì ìˆ˜)**
def search_news(query, top_n=5, similarity_threshold=0.5):  # âœ… ìœ ì‚¬ë„ ê¸°ì¤€ ì™„í™”
    query_keywords = extract_keywords(query, query)
    print(f"âœ… í˜•íƒœì†Œ ë¶„ì„ í›„ í‚¤ì›Œë“œ: {query_keywords}")

    query_vector = model.encode(query_keywords).astype(np.float32)
    news_list = list(collection.find({}))
    results = []

    for news in news_list:
        if "vector" in news and news["vector"]:
            news_vector = np.array(news["vector"], dtype=np.float32)
            similarity = util.cos_sim(query_vector, news_vector).item()
            similarity_percentage = round(similarity * 100, 2)

            # ğŸ”¥ ë¬¸ìì—´ í¬í•¨ ì ìˆ˜ ê³„ì‚°
            text_match_score = compute_text_match_score(query, news["title"])
            combined_score = (0.5 * similarity_percentage) + (0.5 * text_match_score * 100)  # âœ… ê°€ì¤‘ì¹˜ ì¡°ì •

            print(f"ğŸ” '{query}' vs. '{news['title']}' ìœ ì‚¬ë„: {similarity_percentage}% (í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜: {text_match_score * 100:.2f}%) â†’ ìµœì¢… ì ìˆ˜: {combined_score:.2f}%")

            if combined_score >= similarity_threshold * 100:
                news["similarity"] = round(combined_score, 2)
                results.append(news)

    results = sorted(results, key=lambda x: x["similarity"], reverse=True)[:top_n]

    if not results and similarity_threshold > 0.4:
        print("\nâš ï¸ ìœ ì‚¬ë„ 0.5 ì´ìƒ ê²°ê³¼ ì—†ìŒ â†’ ìœ ì‚¬ë„ 0.4ë¡œ ì¬ê²€ìƒ‰")
        return search_news(query, top_n, similarity_threshold=0.4)

    return results


# âœ… ì‹¤í–‰ (ğŸ”¥ í‚¤ì›Œë“œ + ë¶€ë¶„ ê²€ìƒ‰ í¬í•¨)
query = "ì „ì„¸ì‚¬ê³ "
results = search_news(query)

# âœ… ê²°ê³¼ ì¶œë ¥
if results:
    print(f"\nğŸ” ê²€ìƒ‰ì–´ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:")
    for idx, news in enumerate(results, start=1):
        print(f"\n[{idx}] {news['title']}  (ìœ ì‚¬ë„: {news['similarity']}%)")
        print(f"ğŸ“… {news['date']}")
        print(f"ğŸ”— {news['link']}")
        print(f"ğŸ“ {news['summary']}")
        print("-" * 80)
else:
    print(f"\nâŒ ê²€ìƒ‰ì–´ '{query}'ì— ëŒ€í•œ ì ì ˆí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
