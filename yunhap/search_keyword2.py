from sentence_transformers import util
import numpy as np
from pymongo import MongoClient
from transformers import AutoModel, AutoTokenizer
from konlpy.tag import Mecab
import torch
import re

# âœ… MongoDB ì—°ê²°
MONGO_URI = "mongodb://eunbikang:1234@localhost:27017/admin"
client = MongoClient(MONGO_URI)
db = client["admin"]
collection = db["latest_news"]

# âœ… KoBigBird ëª¨ë¸ ë¡œë“œ
MODEL_NAME = "monologg/kobigbird-bert-base"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModel.from_pretrained(MODEL_NAME)

# âœ… Mecab í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œ
mecab = Mecab()

# âœ… **KoBigBird ì„ë² ë”© ìƒì„± í•¨ìˆ˜ (Mean Pooling ì ìš©)**
def get_embedding(text):
    tokens = tokenizer(
        text,
        padding=True,
        truncation=True,
        return_tensors="pt",
        max_length=512
    )
    with torch.no_grad():
        output = model(**tokens)

    # âœ… Mean Pooling ë°©ì‹ ì ìš©
    embedding = output.last_hidden_state.mean(dim=1).squeeze().numpy()
    return embedding / np.linalg.norm(embedding)  # âœ… ë²¡í„° ì •ê·œí™”


# âœ… **í˜•íƒœì†Œ ë¶„ì„ í›„ í‚¤ì›Œë“œ ì¶”ì¶œ (ìµœì†Œ 10ê°œ ë‹¨ì–´ ìœ ì§€)**
def extract_keywords(title, summary):
    # âœ… ì œëª©ê³¼ ìš”ì•½ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ
    title_keywords = mecab.nouns(title) if title else []
    summary_keywords = mecab.nouns(summary) if summary else []

    # âœ… ë³µí•© ëª…ì‚¬ ì²˜ë¦¬
    combined_text = title + " " + summary
    compound_keywords = mecab.nouns(combined_text)  # ì „ì²´ ë¬¸ì¥ì—ì„œ ëª…ì‚¬ ì¶”ì¶œ
    keywords = list(set(title_keywords + summary_keywords + compound_keywords))  # âœ… ì¤‘ë³µ ì œê±°

    # âœ… ì›ë³¸ ê²€ìƒ‰ì–´ê°€ ë³µí•© ëª…ì‚¬ì¼ ê²½ìš° ì¶”ê°€
    if " " not in combined_text.strip():  # ì˜ˆ: "ì „ì„¸ì‚¬ê³ "ì²˜ëŸ¼ ë„ì–´ì“°ê¸° ì—†ëŠ” ê²½ìš°
        keywords.append(combined_text.strip())

    # âœ… ìµœì†Œ 10ê°œ ë‹¨ì–´ ìœ ì§€
    if len(keywords) < 10:
        keywords += combined_text.split()

    keywords = list(set(keywords))  # ìµœì¢… ì¤‘ë³µ ì œê±°
    return " ".join(keywords)


# âœ… **í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜ ê³„ì‚° (ì œëª© 70% + ìš”ì•½ 30%)**
def compute_text_match_score(query, title, summary):
    query_terms = mecab.nouns(query)  # âœ… í˜•íƒœì†Œ ë¶„ì„ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ

    # ğŸ”¹ ì œëª©ì—ì„œì˜ ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ ê³„ì‚° (ê°€ì¤‘ì¹˜ 0.7)
    title_match_count = sum(1 for term in query_terms if re.search(rf"\b{term}\b", title, re.IGNORECASE))
    title_score = (title_match_count / len(query_terms)) if query_terms else 0

    # ğŸ”¹ ìš”ì•½ì—ì„œì˜ ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ ê³„ì‚° (ê°€ì¤‘ì¹˜ 0.3)
    summary_match_count = sum(1 for term in query_terms if re.search(rf"\b{term}\b", summary, re.IGNORECASE))
    summary_score = (summary_match_count / len(query_terms)) if query_terms else 0

    # âœ… ìµœì¢… í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜ = ì œëª©(70%) + ìš”ì•½(30%)
    final_score = (title_score * 0.7) + (summary_score * 0.3)

    print(f"âœ… í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜ ê³„ì‚°: query_terms={query_terms}, title_match_count={title_match_count}, summary_match_count={summary_match_count}, final_score={final_score:.2%}")
    return final_score  # âœ… 0~1 ì‚¬ì´ ê°’ ë°˜í™˜


# âœ… **ìœ ì‚¬ë„ ê¸°ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰ (KoBigBird + BM25 ìµœì í™”)**
def search_news(query, top_n=5, similarity_threshold=0.4):
    query_keywords = extract_keywords(query, query)
    print(f"âœ… í˜•íƒœì†Œ ë¶„ì„ í›„ í‚¤ì›Œë“œ: {query_keywords.split()}")  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì¶œë ¥

    query_vector = get_embedding(query_keywords)  # âœ… KoBigBirdë¡œ ë²¡í„°í™”
    print(f"âœ… ì¿¼ë¦¬ ë²¡í„° ê¸¸ì´: {len(query_vector)}")
    print(f"ğŸ“Š ì¿¼ë¦¬ ë²¡í„° ìƒ˜í”Œ: {query_vector[:5]}")  # ì• 5ê°œ ê°’ ì¶œë ¥

    news_list = list(collection.find({}))
    results = []

    for news in news_list:
        if "vector" in news and news["vector"]:
            news_vector = np.array(news["vector"], dtype=np.float32)
            similarity = util.cos_sim(torch.tensor(query_vector, dtype=torch.float32),
                                      torch.tensor(news_vector, dtype=torch.float32)).item()
            similarity_percentage = round(similarity * 100, 2)

            # âœ… í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜ ê³„ì‚° (title + summary)
            text_match_score = compute_text_match_score(query, news["title"], news.get("summary", ""))

            # âœ… ìµœì¢… ì ìˆ˜ = ë²¡í„° ìœ ì‚¬ë„(60%) + í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜(40%)
            combined_score = (0.6 * similarity_percentage) + (0.4 * text_match_score * 100)

            print(f"ğŸ” '{query}' vs. '{news['title']}' ìœ ì‚¬ë„: {similarity_percentage}% (í…ìŠ¤íŠ¸ í¬í•¨ ì ìˆ˜: {text_match_score * 100:.2f}%) â†’ ìµœì¢… ì ìˆ˜: {combined_score:.2f}%")

            if combined_score >= similarity_threshold * 100:
                news["similarity"] = round(combined_score, 2)
                results.append(news)

    results = sorted(results, key=lambda x: x["similarity"], reverse=True)[:top_n]

    # âœ… ìœ ì‚¬ë„ 0.4 ì´ìƒ ê²°ê³¼ ì—†ì„ ê²½ìš° 0.3ìœ¼ë¡œ ì¬ê²€ìƒ‰
    if not results and similarity_threshold > 0.3:
        print("\nâš ï¸ ìœ ì‚¬ë„ 0.4 ì´ìƒ ê²°ê³¼ ì—†ìŒ â†’ ìœ ì‚¬ë„ 0.3ìœ¼ë¡œ ì¬ê²€ìƒ‰")
        return search_news(query, top_n, similarity_threshold=0.3)

    return results


# âœ… ì‹¤í–‰ (KoBigBird ê¸°ë°˜ ê²€ìƒ‰ ìµœì í™”)
query = "ì „ì„¸ì‚¬ê³ "
results = search_news(query)

# âœ… ê²°ê³¼ ì¶œë ¥
if results:
    print(f"\nğŸ” ê²€ìƒ‰ì–´ '{query}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼:")
    for idx, news in enumerate(results, start=1):
        print(f"\n[{idx}] {news['title']}  (ìœ ì‚¬ë„: {news['similarity']}%)")
        print(f"ğŸ“… {news['date']}")
        print(f"ğŸ”— {news['link']}")
        print(f"ğŸ“ {news['summary']}")
        print("-" * 80)
else:
    print(f"\nâŒ ê²€ìƒ‰ì–´ '{query}'ì— ëŒ€í•œ ì ì ˆí•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
