import os
import requests
from bs4 import BeautifulSoup
import pandas as pd
from tqdm import tqdm  # âœ… ì§„í–‰ ìƒíƒœ í‘œì‹œìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from colorama import Fore


# ë°ì´í„° ì €ì¥ í´ë” ìƒì„±
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

# ê¸°ë³¸ URL ë° ìš”ì²­ í—¤ë” ì„¤ì •
BASE_URL = "https://www.hollys.co.kr/store/korea/korStore2.do"
HEADERS = {"User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"}

def get_store_data(page):
    """ íŠ¹ì • í˜ì´ì§€ì˜ ë§¤ì¥ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ """
    response = requests.get(f"{BASE_URL}?pageNo={page}&sido=&gugun=&store=", headers=HEADERS)
    soup = BeautifulSoup(response.text, "html.parser")

    return [
        { "ì§€ì—­": cols[0].text.strip(), "ë§¤ì¥ëª…": cols[1].text.strip(), "í˜„í™©": cols[2].text.strip(),
          "ì£¼ì†Œ": cols[3].text.strip(), "ì„œë¹„ìŠ¤": ", ".join(img["alt"] for img in cols[4].find_all("img")),
          "ì „í™”ë²ˆí˜¸": cols[5].text.strip() }
        for row in soup.select("table.tb_store tbody tr")
        if (cols := row.find_all("td")) and len(cols) >= 6
    ]

def scrape_all_pages():
    """ ëª¨ë“  í˜ì´ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ CSVë¡œ ì €ì¥ (ì§„í–‰ìƒí™© tqdm í‘œì‹œ) """
    all_stores, page = [], 1

    with tqdm(desc=Fore.GREEN + "í˜ì´ì§€ ìˆ˜ì§‘ ì§„í–‰", colour='cyan', dynamic_ncols=True) as pbar:
        while (stores := get_store_data(page)):
            all_stores.extend(stores)
            pbar.update(1)  # âœ… tqdm ì—…ë°ì´íŠ¸
            pbar.set_postfix({"í˜ì´ì§€": page, "ìˆ˜ì§‘ ë§¤ì¥": len(stores)})
            page += 1

    pd.DataFrame(all_stores).to_csv(os.path.join(DATA_DIR, "hollys_stores.csv"), index=False, encoding="utf-8-sig")
    print(f"\nğŸ“ ì´ {len(all_stores)}ê°œ ë§¤ì¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    scrape_all_pages()
